x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
(8.58-mean(x))/sd(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit <-lm(y~x)
summary(fit)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
library (swirl)
swirl()
fit <-lm(child~parent, data=galton)
1/(n-2)*
View(SmallToothGrowth)
sqrt(sum(fit$residuals^2)/(n-2))
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
mu <- mean(galton$child)
STot<-sum()
sTot <- sum((galton$child-mu)^2)
Sres <-deviance(STot)
View(galton)
Sres <- deviance(fit)
sRes <- deviance(fit)
1-sRes/sTot
summary(fit)$r.squared
cor(galton$child,galton$parent)
cor(galton$child,galton$parent)^2
ones <- rep(1, nrow(galton))
lm(child~ones+parent-1, galton)
lm(child~parent, galton)
lm(child~1, galton)
view(trees)
head(trees)
fit<- lm(Volume ~ Girth + Height+ Constant -1, trees)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~ Height + Constant -1, trees2)
lapply(list(fit, fit2), coef)
all <- lm(Fertility~., swiss)
summary(all)
lm(Fertility~Agriculture, swiss)
summary(lm(Fertility~Agriculture, swiss))
cor(Examination,Education)
cor(Examination, Education, data=swiss)
View(swiss)
cor(swiss$Examination,swiss$Education)
cor(swiss$Agriculture,swiss$Education)
makelms()
ec <- sum(swiss$Examination,swiss$Catholic)
ec <- swiss$Examination+swiss$Catholic
efit <- lm(Fertility~.+ec)
efit <- lm(Fertility~.+ec, data=swiss)
summary(efit)
all$coefficients-efit$coefficients
exit
swirl()
swirl()
library(swirl)
swirl()
view(InsectSprays)
head(InsectSprays)
dim(InsectSprays)
head(InsectSprays,15)
names(sA)
SB
SB
SB
SB
View(InsectSprays)
SB
sB
M[,2]
sA[,e]
sA[,2]
InsectSprays[,2]
summary(InsectSprays[,2])
sapply(InsectSprays)
View(InsectSprays)
sapply(InsectSprays,class)
fit <- lm(count~spray, data=InsectSprays)
summary(fit)
summary(fit)$coef
est<-summary(fit)$coef[,1]
mean(sA)
mean(sB)
nfit <- lm(count~spray-1, data=InsectSprays)
summary(nfit)$coef
View(InsectSprays)
spray2 <- relevel
spray2 <- relevel(InsectSprays$spray, \"c\")
spray2 <- relevel(InsectSprays$spray, \"C\")
spray2 <- relevel(InsectSprays$spray,\"C\")
spray2 <- relevel(InsectSprays$spray,"\C\")
spray2 <- relevel(InsectSprays$spray, reference="C")
spray2 <- relevel(InsectSprays$spray, ref="C")
fit2 <- lm(count~spray, data=InsectSprays)
fit2 <- lm(count~spray2, data=InsectSprays)
summary(fit2)$coef
mean(sC)
(fit$coef[3]-fit$coef[2])/1.6011
(fit$coef[2]-fit$coef[3])/1.6011
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <-lm(y~x)
summary(fit)
library(datasets)
datasets::mtcar
datasets::mtcars
datasets::mtcars
x<-mtcars$wt
y<-mtcars$mpg
fit<-lm(y ~ x)
x<-mtcars$wt
x1<-mtcars$wt
y1<-mtcars$mpg
fit2<-lm(y1 ~ x1)
summary(fit2)
predict(fit2,data.frame(x1=mean(x1)), interval="confidence")
?mtcars
predict(fit2,data.frame(x1=3), interval="prediction")
x1<-mtcars$wt
y1<-mtcars$mpg
fit2<-lm(y1 ~ x1)
summary(fit2)
y <- mtcars$mpg; x <- mtcars$wt
fitWithIntercept <- lm(y ~ x)
yhat1 <- fit$coefficients[1] + x
se1 <- sum((y - yhat1)^2)
yhat2 <- fit$coefficients[1] + fit$coefficients[2] * x
se2 <- sum((y - yhat2)^2)
ratio <- se2 / se1
<- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit<-lm(y~x)
summary(fit)
x1<-mtcars$wt
y1<-mtcars$mpg
fit2<-lm(y1 ~ x1)
summary(fit2)
predict(fit2,data.frame(x1=mean(x1)), interval="confidence")
predict(fit2,data.frame(x1=3), interval="prediction")
fit3<-lm(y1 ~ x1/2)
summary(fit2)
predict(fit2,data.frame(x1=1), interval="confidence")
fit3<-lm(y1 ~ x1/2)
summary(fit3)
predict(fit3,data.frame(x1=1), interval="confidence")
fit3<-lm(y1 ~ x1/2)
fit3<-lm(y1 ~I(x1/2))
summary(fit3)
predict(fit3,data.frame(x1=1), interval="confidence")
y <- mtcars$mpg; x <- mtcars$wt
fitWithIntercept <- lm(y ~ x)
yhat1 <- fit$coefficients[1] + x
se1 <- sum((y - yhat1)^2)
yhat2 <- fit$coefficients[1] + fit$coefficients[2] * x
se2 <- sum((y - yhat2)^2)
ratio <- se2 / se1
library(swirl)
CT
swirl()
dim(hunger)
948
names(hunger)
fit <- lm(Numeric~Year, dataset=hunger)
View(hunger)
fit <- lm(Numeric ~ Year, hunger)
summary(fit)$coef
lmF <- lm(Numeric ~ Year, x[hunger$Sex=="Female"])
View(hunger)
lmF <- lm(hunger$Numeric[hunger$Sex=="Female"]~ hunger$Year[hunger$Sex=="Female"])
lmM <- lm(Numeric[Sex=="Male"], Year[Sex=="Male"], hunger)
lmM <- lm(Numeric[Sex=="Male"]~Year[Sex=="Male"], hunger)
lmBoth <- lm(Numeric~Year+Sex, hunger)
summary(lmBoth)
lmInter<- lm (Numeric~Year+Sex+Sex*Year, hunger)
summary(lmInter)
fit <-lm(y~x, out2)
plot(fit, which=1)
fitno <- lm(y~x, out2[-1,])
plot(fitno, which=1)
coef(fitno)-coef(fit)
coef(fit)-coef(fitno)
head(dfbeta(fit))
resno <- out2[1, "y"] - predict(fitno, out2[1,])
1-resid(fit)[1]/resno
head(hatvalues(fit))
exists()
quit()
library(swirl)
swirl
swirl()
View(out1)
sigma <- sqrt(deviance(fit)/df.residual(fit))
rstd <- rstandard(fit)
head(cbind(rtd, rstandard(fit)))
head(cbind(rstd, rstandard(fit)))
plot(fit, which=3)
plot(fit, which=2)
sigma1 <- sqrt(deviance(fitno)/df.residual(fitno))
resid(fit)[1]/sigma1*sqrt(1-hatvalues(fit)[1])
resid(fit)[1]/(sigma1*sqrt(1-hatvalues(fit)[1]))
head(rstudent(fit)) or View(rstudent(fit))
head(rstudent(fit))
dy <- predict(fitno,out2)- predict(fit, out2)
dy/2*sigma^2
sum(dy^2)/(2*sigma^2)
plot(fit, which=5)
exit()
quit()
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("Hmisc")
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(Hmisc)
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(Cement,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(BlastFurnaceSlag,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(FlyAsh,g=3))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(Water,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(Superplasticizer,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(CoarseAggregate,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(FineAggregate,g=4))
qplot(x = 1:length(inTrain), y = CompressiveStrength, data = training, color = cut2(Age,g=4))
rm(list = ls())
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(Superplasticizer, data = training)
qplot(log(Superplasticizer+1), data = training)
rm(list = ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_str <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.8)
preProc$rotatio
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
## get the confustion matrix for the first method
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
A1 <- C1$overall[1]
## do similar steps with the caret package
modelFit <- train(training$diagnosis ~ ., method = "glm", preProcess = "pca",
data = training, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
A2 <- C2$overall[1]
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
dataframe <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(dataframe$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
testing <- df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
NONPCA <- C1$overall[1]
rm(list = ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
NONPCA <- C1$overall[1]
install.packages("ElemStatLearn")
install.packages("pgmm")
install.packages("rpart")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
data <- segmentationOriginal
set.seed(125)
inTrain <- data$Case == "Train"
trainData <- data[inTrain, ]
testData <- data[!inTrain, ]
cartModel <- train(Class ~ ., data=trainData, method="rpart")
cartModel$finalModel
library(rattle)
fancyRpartPlot(model$finalModel)
fancyRpartPlot(cartmodel$finalModel)
fancyRpartPlot(cartModel$finalModel)
plot(cartModel$finalModel, uniform=T)
text(cartModel$finalModel, cex=0.8)
library(pgmm)
data(olive)
olive = olive[,-1]
treeModel <- train(Area ~ ., data=olive, method="rpart2")
treeModel
newdata <- as.data.frame(t(colMeans(olive)))
predict(treeModel, newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
logitModel <- train(chd ~ age + alcohol + obesity + tobacco +
typea + ldl, data=trainSA, method="glm",
family="binomial")
logitModel <- train(chd ~ age+alcohol+obesity+tobacco+typea+ldl, data=trainSA, method="glm",family="binomial")
logitModel
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predictTrain <- predict(logitModel, trainSA)
predictTest <- predict(logitModel, testSA)
missClass(trainSA$chd, predictTrain)
missClass(trainSA$chd, predictTest)
predictTest <- predict(logitModel, testSA)
missClass(trainSA$chd, predictTest)
missClass(testSA$chd, predictTest)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
library(caret)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
library("randomForest", lib.loc="~/R/win-library/3.2")
library(randomForest)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
imps <- varImp(modelRf)
order(imps)
order(imps)
install.packages("gbm")
install.packages("lubridate")
install.packages("forecast")
install.packages("e1071")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
library(caret)
fitRf <- train(y ~ ., data=vowel.train, method="rf")
fitGBM <- train(y ~ ., data=vowel.train, method="gbm")
predRf <- predict(fitRf, vowel.test)
predGBM <- predict(fitGBM, vowel.test)
confusionMatrix(predRf, vowel.test$y)$overall[1]
confusionMatrix(predGBM, vowel.test$y)$overall[1]
pred <- data.frame(predRf, predGBM, y=vowel.test$y, agree=predRf == predGBM)
accuracy <- sum(predRf[pred$agree] == pred$y[pred$agree]) / sum(pred$agree)
accuracy
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
fitRf <- train(diagnosis ~ ., data=training, method="rf")
fitGBM <- train(diagnosis ~ ., data=training, method="gbm")
fitLDA <- train(diagnosis ~ ., data=training, method="lda")
predRf <- predict(fitRf, testing)
predGBM <- predict(fitGBM, testing)
predLDA <- predict(fitLDA, testing)
pred <- data.frame(predRf, predGBM, predLDA, diagnosis=testing$diagnosis)
fit <- train(diagnosis ~., data=pred, method="rf")
predFit <- predict(fit, testing)
c1 <- confusionMatrix(predRf, testing$diagnosis)$overall[1]
c2 <- confusionMatrix(predGBM, testing$diagnosis)$overall[1]
c3 <- confusionMatrix(predLDA, testing$diagnosis)$overall[1]
c4 <- confusionMatrix(predFit, testing$diagnosis)$overall[1]
print(paste(c1, c2, c3, c4))
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
fit <- train(CompressiveStrength ~ ., data=training, method="lasso")
plot.enet(fit$finalModel, xvar="penalty", use.color=T)
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
fit <- bats(tstrain)
fit
library(forecast)
fit <- bats(tstrain)
fit
pred <- forecast(fit, level=95, h=dim(testing)[1])
names(data.frame(pred))
predComb <- cbind(testing, data.frame(pred))
names(testing)
names(predComb)
predComb$in95 <- (predComb$Lo.95 < predComb$visitsTumblr) &
(predComb$visitsTumblr < predComb$Hi.95)
prop.table(table(predComb$in95))[2]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
fit <- svm(CompressiveStrength ~., data=training)
fit
pred <- predict(fit, testing)
acc <- accuracy(pred, testing$CompressiveStrength)
acc
setwd("D:/project/Assignment/Assignment_8")
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
dir.create("./data")
}
if (!file.exists(trainFile)) {
download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
download.file(testUrl, destfile=testFile, method="curl")
}
setwd("D:/project/Assignment/Assignment_8")
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
dir.create("./data")
}
if (!file.exists(trainFile)) {
download.file(trainUrl, destfile=trainFile, method="curl")
}
if (!file.exists(testFile)) {
download.file(testUrl, destfile=testFile, method="curl")
}
setwd("D:/project/Assignment/Assignment_8")
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
dir.create("./data")
}
if (!file.exists(trainFile)) {
download.file(trainUrl, destfile=trainFile, method="curl",mode="wb")
}
if (!file.exists(testFile)) {
download.file(testUrl, destfile=testFile, method="curl",mode="wb")
}
setwd("D:/project/Assignment/Assignment_8")
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
dir.create("./data")
}
if (!file.exists(trainFile)) {
download.file(trainUrl, destfile=trainFile, method="curl",mode="wb")
}
if (!file.exists(testFile)) {
download.file(testUrl, destfile=testFile, method="curl",mode="wb")
}
if (!file.exists(trainFile)) {
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile="./data/pml-training.csv", method="curl",mode="wb")
if (!file.exists(testFile)) {
download.file(testUrl, destfile=testFile, method="curl",mode="wb")
